{
 "metadata": {
  "name": "",
  "signature": "sha256:4ca7fd29fd4275286900e71b9c0090a0d42b86a9f082e34d652f0b40cff55302"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ale_python_interface import ALEInterface\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import cv2\n",
      "import random\n",
      "from collections import deque\n",
      "\n",
      "import time\n",
      "import os\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "from replayMemory import ReplayMemory\n",
      "import buildGraph"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/cgel/.local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
        "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ale = ALEInterface()\n",
      "viz = False\n",
      "rom_name = \"roms/Breakout.bin\"\n",
      "ale.setBool('sound', False)                                                                                \n",
      "ale.setBool('display_screen', viz) \n",
      "ale.setInt(\"frame_skip\", 4)\n",
      "ale.loadROM(rom_name)\n",
      "legal_actions = ale.getMinimalActionSet()\n",
      "action_map = {}\n",
      "for i in range(len(legal_actions)):\n",
      "    action_map[i] = legal_actions[i]\n",
      "action_num = len(action_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "STEPS_BEFORE_TRAINING = 50000\n",
      "EXPLORE = 1000000. # frames over which to anneal epsilon\n",
      "FINAL_EPSILON = 0.1#0.001 # final value of epsilon\n",
      "INITIAL_EPSILON = 1.0#0.01 # starting value of epsilon\n",
      "BATCH_SIZE = 32 # size of minibatch\n",
      "PARAM_SYNC_STEPS = 10000\n",
      "BUF_SIZE = 4\n",
      "SAVE_SUMMARY_STEPS = 1000\n",
      "\n",
      "class config:\n",
      "    batch_size = 32\n",
      "    replay_memory_capacity = 1000000\n",
      "    buff_size = BUF_SIZE\n",
      "    \n",
      "def get_epsilon():\n",
      "    if global_step < EXPLORE:\n",
      "        return INITIAL_EPSILON - ( (INITIAL_EPSILON-FINAL_EPSILON)/EXPLORE ) * global_step\n",
      "    else:\n",
      "        return FINAL_EPSILON\n",
      "    \n",
      "RM = ReplayMemory(config)\n",
      "\n",
      "learning_rate = 0.00025\n",
      "GAMMA = 0.99"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preprocess(new_frame, state):\n",
      "    frame = cv2.resize(new_frame, (84, 84))\n",
      "    new_state = np.roll(state, -1, axis=3)\n",
      "    new_state[0, :, :, BUF_SIZE -1] = frame\n",
      "    return new_state"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with tf.device(\"/gpu:0\"):\n",
      "    with tf.name_scope(\"DQN\"):\n",
      "        DQN_input_placeholder, DQN, DQN_params = buildGraph.createQNetwork(\"DQN_summaries\", action_num)\n",
      "        #the action with the highest Q$\n",
      "        max_action_DQN = tf.argmax(DQN, 1)\n",
      "        #tf.scalar_summary(\"max_DQN\", max_action_DQN)\n",
      "    with tf.name_scope(\"DQNTarget\"):\n",
      "        DQNT_input_placeholder, DQNT, DQNT_params = buildGraph.createQNetwork(\"DQNT_summaries\", action_num)\n",
      "        #the higest DQNT value\n",
      "        max_DQNT = tf.reduce_max(DQNT, 1)\n",
      "\n",
      "    # DQN summary\n",
      "    for i in range(action_num):\n",
      "        dqni = tf.scalar_summary(\"DQN/action\"+str(i), DQN[0, i])\n",
      "        tf.add_to_collection(\"DQN_summaries\", dqni)\n",
      "\n",
      "    sync_DQNT_op = [DQNT_params[i].assign(DQN_params[i]) for i in range(len(DQN_params))]\n",
      "\n",
      "    # r + Qtarget; is feeded as Y\n",
      "    Y_placeholder = tf.placeholder(tf.float32, [None], name=\"Y_placeholder\")\n",
      "    Action_batch = tf.placeholder(tf.int64, [None], name=\"Action_placholder\")\n",
      "    train_op = buildGraph.build_train_op(DQN, Y_placeholder, Action_batch, action_num, learning_rate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def update_params():\n",
      "    if global_step > STEPS_BEFORE_TRAINING:\n",
      "        state_batch, action_batch, reward_batch, next_state_batch, terminal_batch, _ = RM.sample_transition_batch()\n",
      "        if global_step % SAVE_SUMMARY_STEPS == 0:\n",
      "            DQNT_max_action_batch, DQNT_summary_str = sess.run([max_DQNT, DQNT_summary_op], feed_dict={DQNT_input_placeholder:next_state_batch})\n",
      "        else:\n",
      "            DQNT_max_action_batch = sess.run(max_DQNT, feed_dict={DQNT_input_placeholder:next_state_batch})\n",
      "\n",
      "        Y = []\n",
      "        for i in range(state_batch.shape[0]):\n",
      "            terminal = terminal_batch[i]\n",
      "            if terminal:\n",
      "                Y.append(reward_batch[i])\n",
      "            else:\n",
      "                Y.append(reward_batch[i] + GAMMA * DQNT_max_action_batch[i])\n",
      "                \n",
      "        if global_step % SAVE_SUMMARY_STEPS == 0:\n",
      "            _, DQN_summary_str = sess.run([train_op, DQN_summary_op], feed_dict={Y_placeholder : Y,\n",
      "                                                              Action_batch : action_batch,\n",
      "                                                              DQN_input_placeholder : state_batch})\n",
      "        else:\n",
      "             _ = sess.run(train_op, feed_dict={Y_placeholder : Y,\n",
      "                                                              Action_batch : action_batch,\n",
      "                                                              DQN_input_placeholder : state_batch})           \n",
      "            \n",
      "        if global_step % SAVE_SUMMARY_STEPS == 0:\n",
      "            summary_writter.add_summary(DQNT_summary_str, global_step)\n",
      "            summary_writter.add_summary(DQN_summary_str, global_step)\n",
      "\n",
      "        if global_step % PARAM_SYNC_STEPS == 0:\n",
      "            sess.run(sync_DQNT_op)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sess_config = tf.ConfigProto()\n",
      "sess_config.allow_soft_placement = True\n",
      "sess_config.gpu_options.allow_growth = True\n",
      "sess = tf.InteractiveSession(config=sess_config)\n",
      "saver = tf.train.Saver(max_to_keep = 20)\n",
      "sess.run(tf.initialize_all_variables())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#geneate a new set of paths\n",
      "run_list = os.listdir(\"log\")\n",
      "int_run_list = [int(r) for r in run_list] + [0]\n",
      "run_name = str(max(int_run_list) + 1)\n",
      "#run_name = str(3)\n",
      "checkpoint_path = \"checkpoint/\" + run_name + \".ckpt\"\n",
      "log_path = \"log/\"+ run_name\n",
      "print(run_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "83\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DQN_summary_op = tf.merge_summary(tf.get_collection(\"DQN_summaries\"))\n",
      "DQNT_summary_op = tf.merge_summary(tf.get_collection(\"DQNT_summaries\"))\n",
      "summary_writter = tf.train.SummaryWriter(log_path, sess.graph, flush_secs=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#saver.restore(sess, \"checkpoint/73.ckpt-9000\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def e_greedy_action(epsilon, state):\n",
      "        if np.random.uniform() < epsilon:\n",
      "            action = random.randint(0, action_num - 1)\n",
      "        else:\n",
      "            action = np.argmax(sess.run(DQN, feed_dict={DQN_input_placeholder:state})[0])\n",
      "        return action\n",
      "    \n",
      "def greedy_run(epsilon, n):\n",
      "    ale.reset_game()\n",
      "    R_list = []\n",
      "    for episode in range(n):\n",
      "        state = np.zeros((1, 84, 84, BUF_SIZE), dtype=np.uint8)\n",
      "        state = preprocess(ale.getScreenGrayscale(), state)\n",
      "        R = 0\n",
      "        while ale.game_over() == False:\n",
      "            action = e_greedy_action(epsilon, state)\n",
      "            reward = ale.act(action_map[action])\n",
      "            state = preprocess(ale.getScreenGrayscale(), state)\n",
      "            R += reward\n",
      "        R_list.append(R)\n",
      "        ale.reset_game()\n",
      "    return R_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "global_step = 0\n",
      "global_episode = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "num_episodes = 10000\n",
      "initial_episode = global_episode\n",
      "for episode in range(global_episode, num_episodes + global_episode):\n",
      "    global state\n",
      "    state = np.zeros((1, 84, 84, BUF_SIZE), dtype=np.uint8)\n",
      "    state = preprocess(ale.getScreenGrayscale(), state)\n",
      "    R = 0\n",
      "    ep_begin_t = time.time()\n",
      "    isTerminal = False\n",
      "    episode_begining_step = global_step\n",
      "    while isTerminal == False:\n",
      "        action = e_greedy_action(get_epsilon(), state)\n",
      "        reward = ale.act(action_map[action])\n",
      "        clipped_reward = max(-1, min(1, reward))\n",
      "        R += reward\n",
      "        if ale.game_over():\n",
      "            isTerminal = True\n",
      "        RM.add(state[0, :, :, BUF_SIZE -1], action, clipped_reward, isTerminal)\n",
      "        update_params()\n",
      "        state = preprocess(ale.getScreenGrayscale(), state)\n",
      "        global_step += 1\n",
      "    ep_duration = time.time() - ep_begin_t\n",
      "    if episode%500 == 0:\n",
      "        episode_online_summary = tf.Summary(value=[tf.Summary.Value(tag=\"online/epsilon\", simple_value=get_epsilon()), \n",
      "                                    tf.Summary.Value(tag=\"online/R\", simple_value=R),\n",
      "                                    tf.Summary.Value(tag=\"online/steps_in_episode\", simple_value= global_step - episode_begining_step),\n",
      "                                    tf.Summary.Value(tag=\"online/global_step\", simple_value = global_step),\n",
      "                                    tf.Summary.Value(tag=\"online/ep_duration_seconds\", simple_value=ep_duration)])\n",
      "        summary_writter.add_summary(episode_online_summary, global_episode)\n",
      "    # log percent\n",
      "    if episode%500 == 0:\n",
      "        percent = int(float(episode - initial_episode)/num_episodes * 100)\n",
      "        print(\"%i%% -- epsilon:%.2f -- step:%i\"%(percent, get_epsilon(), global_step))\n",
      "        \n",
      "    # save\n",
      "    if episode%1000 == 0 and episode != 0 or num_episodes == episode:\n",
      "        print(\"saving checkpoint at episode \" + str(episode))\n",
      "        saver.save(sess, checkpoint_path, episode)\n",
      "        \n",
      "    # performance summary\n",
      "    if episode%1000 == 0:\n",
      "        R_list = greedy_run(epsilon = 0.05, n=10)\n",
      "        performance_summary = tf.Summary(value=[tf.Summary.Value(tag=\"R/average\", simple_value=sum(R_list)/len(R_list)),\n",
      "                                      tf.Summary.Value(tag=\"R/max\", simple_value=max(R_list)),\n",
      "                                      tf.Summary.Value(tag=\"R/min\", simple_value=min(R_list))])\n",
      "        summary_writter.add_summary(performance_summary, global_step)\n",
      "        \n",
      "    global_episode += 1\n",
      "    ale.reset_game()\n",
      "    \n",
      "print(\"==\")\n",
      "print((time.time() - t)/60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RM_path = \"checkpoint/RM_\"+run_name+\"_\"+str(global_step)\n",
      "def RM_save(self):\n",
      "    name_array = zip(['actions', 'rewards',  'screens',  'terminals',  'state_batch',  'next_state_batch'],\n",
      "        [self.actions, self.rewards, self.screens, self.terminals, self.state_batch, self.next_state_batch])\n",
      "    for idx, (name, array) in enumerate(name_array):\n",
      "        np.save(RM_path+name, array)\n",
      "    \n",
      "def RM_load():\n",
      "    self = ReplayMemory(config)\n",
      "    name_array = zip(['actions', 'rewards',  'screens',  'terminals',  'state_batch',  'next_state_batch'],\n",
      "        [self.actions, self.rewards, self.screens, self.terminals, self.state_batch, self.next_state_batch])\n",
      "    self.filled = True\n",
      "    for idx, (name, array) in enumerate(name_array):\n",
      "        array[:] = np.load(RM_path+name+\".npy\")\n",
      "    return self\n",
      "\n",
      "def RM_info(RM):\n",
      "    print(\"current :\"+str(RM.current))\n",
      "    print(\"step :\"+str(RM.step))\n",
      "    print(\"capacity :\"+str(RM.capacity))\n",
      "    print(\"filled :\"+str(RM.filled))\n",
      "    print(\"batch_size :\"+str(RM.batch_size))\n",
      "    \n",
      "print(RM_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "checkpoint/RM_29_1640904\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saver.save(sess, checkpoint_path, episode)\n",
      "print(checkpoint_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "checkpoint/62.ckpt\n"
       ]
      }
     ],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saver.restore(sess, checkpoint_path+\"-\"+str(episode))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 468
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "greedy_run(0.05, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 470,
       "text": [
        "[9, 5]"
       ]
      }
     ],
     "prompt_number": 470
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(10000):\n",
      "    update_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 471
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "color = \"Greys_r\"\n",
      "def show_state(state):\n",
      "    fig = plt.figure()\n",
      "    for i in range(0, 4):\n",
      "        a=fig.add_subplot(1,4,i+1)\n",
      "        plt.axis(\"off\")\n",
      "        plt.title(str(i))\n",
      "        plt.imshow(state[:,:,i], color)\n",
      "\n",
      "def show_frame(frame):\n",
      "    fig = plt.figure()\n",
      "    plt.axis(\"off\")\n",
      "    if len(frame.shape) == 2:\n",
      "        plt.imshow(frame, color)\n",
      "    elif len(frame.shape) == 3:\n",
      "        plt.imshow(frame[:,:,BUF_SIZE -1], color)\n",
      "    elif len(frame.shape) == 4:\n",
      "        plt.imshow(frame[0, :,:,BUF_SIZE -1], color)\n",
      "    else:\n",
      "        print(\"Wrong shape\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_state(state[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAB0CAYAAABzPQKjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7efdfc1e0a90>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RM2 = ReplayMemory(config)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "maxQ = []\n",
      "Qs = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ale.reset_game()\n",
      "state = np.zeros((1, 84, 84, BUF_SIZE), dtype=np.uint8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = 0\n",
      "while ale.game_over() == False and c < 10:\n",
      "    raw_frame = ale.getScreenGrayscale()\n",
      "    prev_state = state\n",
      "    state = preprocess(raw_frame, state)\n",
      "    current_DQN =  sess.run(DQN, feed_dict={DQN_input_placeholder:state})[0]\n",
      "    Qs.append(current_DQN)\n",
      "    maxQ.append(np.max(current_DQN))\n",
      "    action = np.argmax(current_DQN)\n",
      "    if np.random.uniform() < 0.05:\n",
      "        action = random.randint(0, action_num - 1)\n",
      "    isTerminal = ale.game_over()\n",
      "    #print(np.max(current_DQN))\n",
      "    #print(action)\n",
      "\n",
      "    reward = ale.act(action_map[action])\n",
      "    #print(reward)\n",
      "    R += reward\n",
      "    c += 1\n",
      "plt.plot(maxQ, color=\"red\")\n",
      "plt.plot(Qs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(1000):\n",
      "    update_params2()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 412
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def update_params2():\n",
      "    if global_step > STEPS_BEFORE_TRAINING:\n",
      "        state_batch, action_batch, reward_batch, next_state_batch, terminal_batch, _ = RM2.sample_transition_batch()\n",
      "        if global_step % SAVE_SUMMARY_STEPS == 0:\n",
      "            DQNT_max_action_batch, DQNT_summary_str = sess.run([max_DQNT, DQNT_summary_op], feed_dict={DQNT_input_placeholder:next_state_batch})\n",
      "        else:\n",
      "            DQNT_max_action_batch = sess.run(max_DQNT, feed_dict={DQNT_input_placeholder:next_state_batch})\n",
      "\n",
      "        Y = []\n",
      "        for i in range(state_batch.shape[0]):\n",
      "            terminal = terminal_batch[i]\n",
      "            if terminal:\n",
      "                Y.append(reward_batch[i])\n",
      "            else:\n",
      "                Y.append(reward_batch[i] + GAMMA * DQNT_max_action_batch[i])\n",
      "                \n",
      "        if global_step % SAVE_SUMMARY_STEPS == 0:\n",
      "            _, DQN_summary_str = sess.run([train_op, DQN_summary_op], feed_dict={Y_placeholder : Y,\n",
      "                                                              Action_batch : action_batch,\n",
      "                                                              DQN_input_placeholder : state_batch})\n",
      "        else:\n",
      "             _ = sess.run(train_op, feed_dict={Y_placeholder : Y,\n",
      "                                                              Action_batch : action_batch,\n",
      "                                                              DQN_input_placeholder : state_batch})           \n",
      "            \n",
      "        if global_step % SAVE_SUMMARY_STEPS == 0:\n",
      "            summary_writter.add_summary(DQNT_summary_str, global_step)\n",
      "            summary_writter.add_summary(DQN_summary_str, global_step)\n",
      "\n",
      "        if global_step % PARAM_SYNC_STEPS == 0:\n",
      "            sess.run(sync_DQNT_op)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ale.act(actio)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ale-old.ipynb."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}